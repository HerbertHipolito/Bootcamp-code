{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCaOYb0iUubx"
      },
      "source": [
        "#Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "WO6vu8jNUXkv"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('always')\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Nadam, Adam\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from keras.layers import Dropout, Flatten, Input, Dense\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import os\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzMIYSgpVAa5"
      },
      "source": [
        "#Classes and Functions used"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NWI6FpiXJfF"
      },
      "source": [
        "##Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AgfImyz4VEoJ"
      },
      "outputs": [],
      "source": [
        "def display_img(image,title='Image',x_label=None,y_label=None,cmap_type='gray',show_axis=False,colorBar=False,F_size=(8,6)):\n",
        "  plt.figure(figsize=F_size)\n",
        "  plt.imshow(image,cmap=cmap_type)\n",
        "  plt.title(title)\n",
        "  plt.xlabel(x_label)\n",
        "  plt.ylabel(y_label)\n",
        "  if colorBar: plt.colorbar()\n",
        "  if not show_axis: plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "def show_graphs(curve1,curve2,title,xlabel,ylabel):\n",
        "\n",
        "  plt.plot(curve1)\n",
        "  plt.plot(curve2)\n",
        "  plt.title(f'Model {title}')\n",
        "  plt.ylabel(xlabel)\n",
        "  plt.xlabel(ylabel)\n",
        "  plt.legend(['train', 'validation'])\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKC1jew9VHBZ"
      },
      "source": [
        "#Loading the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Il_8yjC2VKVI",
        "outputId": "293c7953-862c-4b6b-8aad-190fb519fbac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of cropped maligno images: 261\n",
            "Number of cropped benigno images: 276\n"
          ]
        }
      ],
      "source": [
        "#select_images_randomly = False\n",
        "\n",
        "#Get images from google drive\n",
        "directory_path_malignos = '/content/drive/MyDrive/BootcampFinal/cropped_and_treated_100_nods_maligno/'\n",
        "directory_path_benignos = '/content/drive/MyDrive/BootcampFinal/cropped_and_treated_100_nods_benigno/'\n",
        "\n",
        "directory_files = os.listdir(directory_path_malignos)\n",
        "array_of_images_malignos = [plt.imread( os.path.join(directory_path_malignos,file),format='.png' ) for file in directory_files]\n",
        "\n",
        "directory_files = os.listdir(directory_path_benignos)\n",
        "array_of_images_benignos = [plt.imread( os.path.join(directory_path_benignos,file),format='.png' ) for file in directory_files]\n",
        "\n",
        "array_of_images_malignos.pop(0)\n",
        "\n",
        "print(f'Number of cropped maligno images: {len(array_of_images_malignos)}')\n",
        "print(f'Number of cropped benigno images: {len(array_of_images_benignos)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEmZrSWSP1fO"
      },
      "source": [
        "##Data augmentation\n",
        "\n",
        "Only execute the first cell below after cleaning up the folder that will store the new images. Otherwise, it will merge the new dataset with the previous one. To prevent that misuse, I commented out the folder path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzpTOPa8LGhB"
      },
      "outputs": [],
      "source": [
        "batch_size = 2\n",
        "loop_number = 30\n",
        "\n",
        "array_of_images_malignos_tf = tf.expand_dims(array_of_images_malignos,axis=-1)\n",
        "array_of_images_benignos_tf = tf.expand_dims(array_of_images_benignos,axis=-1)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        zoom_range = 0.1, # Aleatory zoom\n",
        "        rotation_range= 45, \n",
        "        width_shift_range=0.2,  # horizontal shift\n",
        "        height_shift_range=0.2,  # vertical shift\n",
        "        horizontal_flip=True,  \n",
        "        vertical_flip=True)\n",
        "\n",
        "datagen.fit(array_of_images_malignos_tf)\n",
        "\n",
        "count = 0\n",
        "\n",
        "new_images_malignos_y,new_images_benignos_y = [],[]\n",
        "\n",
        "#save_to_dir=\"/content/drive/MyDrive/BootcampFinal/generated_malignos_img/\"\n",
        "for batch in datagen.flow(array_of_images_malignos_tf, batch_size=batch_size, save_format='png'):\n",
        "    count += 1\n",
        "    for index in range(batch_size):    \n",
        "      new_images_malignos_y.append(1)\n",
        "    if count >= loop_number:\n",
        "        break\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        zoom_range = 0.1, # Aleatory zoom\n",
        "        rotation_range= 40, \n",
        "        width_shift_range=0.1,  # horizontal shift\n",
        "        height_shift_range=0.1,  # vertical shift\n",
        "        horizontal_flip=True,  \n",
        "        vertical_flip=True)\n",
        "\n",
        "datagen.fit(array_of_images_benignos_tf)\n",
        "\n",
        "count = 0\n",
        "\n",
        "new_images_x,new_images_y = [],[]\n",
        "\n",
        "#save_to_dir=\"/content/drive/MyDrive/BootcampFinal/generated_benignos_img/\"\n",
        "for batch in datagen.flow(array_of_images_benignos_tf, batch_size=batch_size, save_format='png'):\n",
        "    count += 1\n",
        "    for index in range(batch_size):    \n",
        "      new_images_benignos_y.append(0)\n",
        "    if count >= loop_number:\n",
        "        break\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rw-zvJXNPDwq",
        "outputId": "3bbd9fb5-bdf9-403e-d2d0-a62b9ca391f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of cropped maligno images: 60\n",
            "Number of cropped benigno images: 60\n"
          ]
        }
      ],
      "source": [
        "generated_malignos_img = \"/content/drive/MyDrive/BootcampFinal/generated_malignos_img/\"\n",
        "generated_benignos_img = \"/content/drive/MyDrive/BootcampFinal/generated_benignos_img/\"\n",
        "\n",
        "directory_files = os.listdir(generated_malignos_img)\n",
        "new_images_malignos = [plt.imread( os.path.join(generated_malignos_img,file) ) for file in directory_files]\n",
        "\n",
        "directory_files = os.listdir(generated_benignos_img)\n",
        "new_images_benignos = [plt.imread( os.path.join(generated_benignos_img,file) ) for file in directory_files]\n",
        "\n",
        "print(f'Number of cropped maligno images: {len(new_images_malignos)}')\n",
        "print(f'Number of cropped benigno images: {len(new_images_benignos)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzTNG1FhVRWQ"
      },
      "source": [
        "#Spliting the dataset into training and test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3OcUd3YVRdg",
        "outputId": "fa6e56a3-f8b0-4386-c98d-e58d45d742f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of training set 429\n",
            "class 0 size: 212 class 1 size: 217. ratio: 0.5058275058275058\n",
            "Size of test set 108\n",
            "class 0 size: 50 class 1 size: 58. ratio: 0.5370370370370371\n"
          ]
        }
      ],
      "source": [
        "use_augmentation = False\n",
        "\n",
        "if use_augmentation:\n",
        "  x = np.array([*array_of_images_malignos,*array_of_images_benignos,*new_images_malignos,*new_images_benignos])\n",
        "  y = np.array([*[1 for _ in array_of_images_malignos],*[0 for _ in array_of_images_benignos],*[1 for _ in new_images_malignos],*[0 for _ in new_images_benignos]])\n",
        "else:\n",
        "  x = np.array([*array_of_images_malignos,*array_of_images_benignos])\n",
        "  y = np.array([*[1 for _ in array_of_images_malignos],*[0 for _ in array_of_images_benignos]])\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42,shuffle=True)\n",
        "x_test_tranformed = np.array([cv2.cvtColor(img,cv2.COLOR_GRAY2RGB) for img in x_test]) \n",
        "\n",
        "x_train = tf.expand_dims(x_train, axis=-1)\n",
        "x_test = tf.expand_dims(x_test, axis=-1)\n",
        "y_train = tf.expand_dims(y_train, axis=-1)\n",
        "y_test = tf.expand_dims(y_test, axis=-1)\n",
        "x_test_tranformed = tf.expand_dims(x_test_tranformed, axis=-1)\n",
        "\n",
        "print(f'Size of training set {len(y_train)}')\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "count_result= dict(zip(unique, counts))\n",
        "print(f'class 0 size: {count_result[0]} class 1 size: {count_result[1]}. ratio: {count_result[1]/(count_result[0]+count_result[1])}')\n",
        "\n",
        "print(f'Size of test set {len(y_test)}')\n",
        "unique, counts = np.unique(y_test, return_counts=True)\n",
        "count_result= dict(zip(unique, counts))\n",
        "print(f'class 0 size: {count_result[0]} class 1 size: {count_result[1]}. ratio: {count_result[1]/(count_result[0]+count_result[1])}')\n",
        "\n",
        "x_train = np.array([*x_train,])\n",
        "y_train = np.array([*y_train,])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQuFrD--XDY-"
      },
      "source": [
        "#Building the model and perfoming the simulations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2yWl_ZrKtEm"
      },
      "source": [
        "##Performing simulations\n",
        "\n",
        "About All layers provided by Keras: https://keras.io/api/layers/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g39tvM935Nq5"
      },
      "source": [
        "###Setting up the architectures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SPrJUFHl9xSr"
      },
      "outputs": [],
      "source": [
        "architectures = {\n",
        "    'simulation1':{\n",
        "      'layers':{\n",
        "          'layer_1':{\n",
        "              'type':'conv2',\n",
        "              'parameters':{'filters':16,'kernel_size':9,'padding':'same','activation':'relu','input_shape': (98,98,1)}\n",
        "          },\n",
        "          'layer_2':{\n",
        "              'type':'maxPooling',\n",
        "              'parameters':{'pool_size':[2,2],'strides':2}\n",
        "          },\n",
        "          'layer_3':{\n",
        "              'type':'conv2',\n",
        "              'parameters':{'filters':32,'kernel_size':5,'padding':'same','activation':'relu'}\n",
        "          },\n",
        "          'layer_4':{\n",
        "              'type':'maxPooling',\n",
        "              'parameters':{'pool_size':[2,2],'strides':2}\n",
        "          },\n",
        "          'layer_5':{\n",
        "              'type':'conv2',\n",
        "              'parameters':{'filters':64,'kernel_size':3,'padding':'same','activation':'relu'}\n",
        "          },\n",
        "          'layer_6':{\n",
        "              'type':'maxPooling',\n",
        "              'parameters':{'pool_size':[2,2],'strides':2}\n",
        "          },\n",
        "          'layer_7':{\n",
        "              'type':'flatten',\n",
        "              'parameters':None\n",
        "          },\n",
        "          'layer_8':{\n",
        "              'type':'dense',\n",
        "              'parameters':{'units':15,'activation':'relu'}\n",
        "          },\n",
        "          'layer_9':{\n",
        "              'type':'dense',\n",
        "              'parameters':{'units':10,'activation':'relu'}\n",
        "          },\n",
        "          'layer_10':{\n",
        "              'type':'dense',\n",
        "              'parameters':{'units':2,'activation':'softmax'}\n",
        "          }\n",
        "       },\n",
        "      'compile':{'loss':'sparse_categorical_crossentropy','metrics':['accuracy']},\n",
        "      'fit':{'epochs':150,'initial_epoch':0,'validation_split':0.3}\n",
        "    },\n",
        "    'simulation2':{\n",
        "      'layers':{\n",
        "          'layer_1':{\n",
        "              'type':'conv2',\n",
        "              'parameters':{'filters':16,'kernel_size':9,'padding':'same','activation':'relu','input_shape': (98,98,1)}\n",
        "          },\n",
        "          'layer_2':{\n",
        "              'type':'maxPooling',\n",
        "              'parameters':{'pool_size':[2,2],'strides':2}\n",
        "          }\n",
        "         ,\n",
        "          'layer_3':{\n",
        "              'type':'conv2',\n",
        "              'parameters':{'filters':32,'kernel_size':5,'padding':'same','activation':'relu'}\n",
        "          },\n",
        "          'layer_4':{\n",
        "              'type':'maxPooling',\n",
        "              'parameters':{'pool_size':[2,2],'strides':2}\n",
        "          },\n",
        "          'layer_5':{\n",
        "              'type':'flatten',\n",
        "              'parameters':None\n",
        "          },\n",
        "          'layer_6':{\n",
        "              'type':'dense',\n",
        "              'parameters':{'units':15,'activation':'relu'}\n",
        "          },\n",
        "          'layer_7':{\n",
        "              'type':'dense',\n",
        "              'parameters':{'units':10,'activation':'relu'}\n",
        "          },\n",
        "          'layer_8':{\n",
        "              'type':'dense',\n",
        "              'parameters':{'units':2,'activation':'softmax'}\n",
        "          }\n",
        "       },\n",
        "      'compile':{'loss':'sparse_categorical_crossentropy','metrics':['accuracy']},\n",
        "      'fit':{'epochs':150,'initial_epoch':0,'validation_split':0.3}\n",
        "    },\n",
        "    'simulation3':{\n",
        "      'layers':{\n",
        "          'layer_1':{\n",
        "              'type':'conv2',\n",
        "              'parameters':{'filters':64,'kernel_size':9,'padding':'same','activation':'relu','input_shape': (98,98,1)}\n",
        "          },\n",
        "          'layer_2':{\n",
        "              'type':'AveragePooling',\n",
        "              'parameters':{'pool_size':[2,2],'strides':2}\n",
        "          },\n",
        "          'layer_3':{\n",
        "              'type':'conv2',\n",
        "              'parameters':{'filters':48,'kernel_size':5,'padding':'same','activation':'relu'}\n",
        "          },\n",
        "          'layer_4':{\n",
        "              'type':'maxPooling',\n",
        "              'parameters':{'pool_size':[2,2],'strides':2}\n",
        "          },\n",
        "          'layer_5':{\n",
        "              'type':'conv2',\n",
        "              'parameters':{'filters':32,'kernel_size':3,'padding':'same','activation':'relu'}\n",
        "          },\n",
        "          'layer_6':{\n",
        "              'type':'AveragePooling',\n",
        "              'parameters':{'pool_size':[2,2],'strides':2}\n",
        "          },\n",
        "          'layer_7':{\n",
        "              'type':'flatten',\n",
        "              'parameters':None\n",
        "          },\n",
        "          'layer_8':{\n",
        "              'type':'dense',\n",
        "              'parameters':{'units':25,'activation':'relu'}\n",
        "          },\n",
        "          'layer_9':{\n",
        "              'type':'dense',\n",
        "              'parameters':{'units':15,'activation':'relu'}\n",
        "          },\n",
        "          'layer_10':{\n",
        "              'type':'dense',\n",
        "              'parameters':{'units':10,'activation':'relu'}\n",
        "          },\n",
        "          'layer_11':{\n",
        "              'type':'dense',\n",
        "              'parameters':{'units':2,'activation':'softmax'}\n",
        "          }\n",
        "       },\n",
        "      'compile':{'loss':'sparse_categorical_crossentropy','metrics':['accuracy']},\n",
        "      'fit':{'epochs':150,'initial_epoch':0,'validation_split':0.3}\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB4kWCAHj2Vq"
      },
      "source": [
        "###Simulations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0NoMLIqDwxQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1a40905-70dd-458c-ca08-ddbf11dad548"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Performing the simulation1:\n",
            "\n",
            "\n",
            "loop: 0:\n"
          ]
        }
      ],
      "source": [
        "qtd_simulations = 1\n",
        "\n",
        "results = {key:{'accuracy':[],'recall':[],'precision':[],'time_used_to_train':[]} for key in architectures.keys()}\n",
        "\n",
        "skf = StratifiedKFold(n_splits=3)\n",
        "\n",
        "for train_index, test_index in skf.split(x, y):\n",
        "  \n",
        "  x_train, x_test = x[train_index], x[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "  for key in architectures:\n",
        "    \n",
        "    print(f'\\n\\nPerforming the {key}:\\n\\n')\n",
        "\n",
        "    for index in range(qtd_simulations):\n",
        "\n",
        "      print(f'loop: {index}:')\n",
        "      model = keras.Sequential()\n",
        "\n",
        "      for layer_number in architectures[key]['layers']:\n",
        "\n",
        "        if architectures[key]['layers'][layer_number]['type'] == 'conv2':\n",
        "          model.add(keras.layers.Conv2D( **architectures[key]['layers'][layer_number]['parameters'] ))\n",
        "          continue\n",
        "\n",
        "        if architectures[key]['layers'][layer_number]['type'] == 'maxPooling':\n",
        "          model.add(keras.layers.MaxPooling2D(**architectures[key]['layers'][layer_number]['parameters']))\n",
        "          continue\n",
        "        \n",
        "        if architectures[key]['layers'][layer_number]['type'] == 'AveragePooling':\n",
        "          model.add(keras.layers.AveragePooling2D(**architectures[key]['layers'][layer_number]['parameters']))\n",
        "          continue\n",
        "\n",
        "        if architectures[key]['layers'][layer_number]['type'] == 'BatchNormalization':\n",
        "          model.add(keras.layers.BatchNormalization())\n",
        "          continue\n",
        "\n",
        "        if architectures[key]['layers'][layer_number]['type'] == 'flatten':\n",
        "          model.add(keras.layers.Flatten())\n",
        "          continue\n",
        "\n",
        "        if architectures[key]['layers'][layer_number]['type'] == 'dense':\n",
        "          model.add(Dense(**architectures[key]['layers'][layer_number]['parameters']))\n",
        "          continue\n",
        "        \n",
        "        print('Samething went wrong')\n",
        "      \n",
        "      #model.summary()\n",
        "      callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.01,patience=28,restore_best_weights=False) \n",
        "      start = time.time()\n",
        "      model.compile(**architectures[key]['compile'])\n",
        "      history = model.fit(x_train,y_train,**architectures[key]['fit'],verbose=0,callbacks=[callback])\n",
        "      end = time.time()\n",
        "\n",
        "      show_graphs(history.history['loss'],history.history['val_loss'],'Loss','Loss','Epochs')\n",
        "      show_graphs(history.history['accuracy'],history.history['val_accuracy'],'accuracy','accuracy','Epochs')\n",
        "\n",
        "      result = model.evaluate(x_test,y_test)\n",
        "      time_used = end-start\n",
        "      \n",
        "      prediction_result = model.predict(x_test)\n",
        "      prediction_result_tranformed = [0 if number[0]>number[1] else 1 for number in prediction_result]\n",
        "\n",
        "      accuracy = accuracy_score(y_test,prediction_result_tranformed)\n",
        "      recall = recall_score(y_test,prediction_result_tranformed)\n",
        "      precision = precision_score(y_test,prediction_result_tranformed)\n",
        "\n",
        "      results[key]['accuracy'].append(accuracy)\n",
        "      results[key]['recall'].append(recall)\n",
        "      results[key]['precision'].append(precision)\n",
        "\n",
        "      results[key]['time_used_to_train'].append(time_used)\n",
        "      \n",
        "      print(results[key])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results.keys()\n",
        "\n",
        "agrouped_result = dict()\n",
        "\n",
        "for simulation in results.keys():\n",
        "\n",
        "  agrouped_result[simulation] = dict()\n",
        "\n",
        "  for metric in results[simulation].keys():\n",
        "    \n",
        "    agrouped_result[simulation][metric] = dict()\n",
        "    agrouped_result[simulation][metric]['mean'] = np.mean(results[simulation][metric])\n",
        "    agrouped_result[simulation][metric]['std'] = np.std(results[simulation][metric])\n",
        "\n",
        "print(agrouped_result)"
      ],
      "metadata": {
        "id": "FTEbwtV0Rf39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(agrouped_result)"
      ],
      "metadata": {
        "id": "sIsvjjRcSyzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQpE6GOaz9Ba"
      },
      "source": [
        "### VGG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTGMMW6m0EYp"
      },
      "outputs": [],
      "source": [
        "vgg16_architectures = {\n",
        "    'simulation1':{\n",
        "        'layer_1':{\n",
        "            'units':1024,\n",
        "            'activation':'relu'\n",
        "        },\n",
        "        'layer_2':{\n",
        "            'units':512,\n",
        "            'activation':'relu'\n",
        "        },\n",
        "        'layer_3':{\n",
        "            'units':30,\n",
        "            'activation':'relu'\n",
        "        }\n",
        "    },\n",
        "    'simulation2':{\n",
        "        'layer_1':{\n",
        "            'units':512,\n",
        "            'activation':'relu'\n",
        "        },\n",
        "        'layer_2':{\n",
        "            'units':256,\n",
        "            'activation':'relu'\n",
        "        },\n",
        "        'layer_3':{\n",
        "            'units':30,\n",
        "            'activation':'relu'\n",
        "        }\n",
        "    },\n",
        "    'simulation3':{\n",
        "        'layer_1':{\n",
        "            'units':1024,\n",
        "            'activation':'relu'\n",
        "        },\n",
        "        'layer_3':{\n",
        "            'units':30,\n",
        "            'activation':'relu'\n",
        "        }\n",
        "    },\n",
        "    'simulation4':{\n",
        "        'layer_1':{\n",
        "            'units':340,\n",
        "            'activation':'relu'\n",
        "        },\n",
        "        'layer_2':{\n",
        "            'units':150,\n",
        "            'activation':'relu'\n",
        "        },\n",
        "        'layer_3':{\n",
        "            'units':30,\n",
        "            'activation':'relu'\n",
        "        }\n",
        "    },\n",
        "    'simulation5':{\n",
        "        'layer_1':{\n",
        "            'units':300,\n",
        "            'activation':'relu'\n",
        "        },\n",
        "        'layer_2':{\n",
        "            'units':100,\n",
        "            'activation':'relu'\n",
        "        },\n",
        "        'layer_3':{\n",
        "            'units':10,\n",
        "            'activation':'relu'\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "vgg16_result = {simulation_number:{'results':{'accuracy':[],'recall':[],'precision':[]},'time_used_to_evaluate':[]} for simulation_number in vgg16_architectures.keys()}\n",
        "qtd_simulations = 5\n",
        "\n",
        "for simulation_number in vgg16_architectures:\n",
        "\n",
        "  for index in range(qtd_simulations):\n",
        "\n",
        "    vgg = VGG16(input_shape=(44, 44, 3), include_top = False, weights= 'imagenet')\n",
        "    x = vgg.output\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    for layer in vgg16_architectures[simulation_number]:\n",
        "\n",
        "      x = Dense(**vgg16_architectures[simulation_number][layer])(x) \n",
        "      #x = Dropout(0.5)(x)\n",
        "      out = Dense(2,activation='softmax')(x)\n",
        "      tf_model=Model(inputs=vgg.input,outputs=out)\n",
        "\n",
        "      for layer in tf_model.layers[:20]:\n",
        "          layer.trainable=False\n",
        "\n",
        "    #tf_model.summary()\n",
        "\n",
        "    adam = Adam()\n",
        "    tf_model.compile(loss='sparse_categorical_crossentropy',\n",
        "                  optimizer=adam,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    #checkpoint = ModelCheckpoint(filepath='mymodel.h5', \n",
        "    #                               verbose=2, save_best_only=True)\n",
        "\n",
        "    result = tf_model.evaluate(x_test_tranformed,y_test)\n",
        "    #time_used = end-start\n",
        "      \n",
        "    prediction_result = tf_model.predict(x_test_tranformed)\n",
        "    prediction_result_tranformed = [0 if number[0]>number[1] else 1 for number in prediction_result]\n",
        "\n",
        "    accuracy = accuracy_score(prediction_result_tranformed,y_test)\n",
        "    recall = recall_score(prediction_result_tranformed,y_test)\n",
        "    precision = precision_score(prediction_result_tranformed,y_test)\n",
        "    \n",
        "    vgg16_result[simulation_number]['results']['accuracy'].append(accuracy)\n",
        "    vgg16_result[simulation_number]['results']['recall'].append(recall)\n",
        "    vgg16_result[simulation_number]['results']['precision'].append(precision)\n",
        "\n",
        "    print(result,accuracy,recall,precision)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "LCaOYb0iUubx",
        "EzMIYSgpVAa5"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}